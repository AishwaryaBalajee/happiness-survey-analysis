# Happiness Survey Analysis & Prediction

This project analyzes the **ACME Happiness Survey 2020** dataset to explore the factors influencing happiness and build machine learning models to predict survey responses.

## ğŸ“Œ Project Overview
- **Exploratory Data Analysis (EDA):**
  - Univariate, bivariate, and multivariate analysis
  - Visualization of feature distributions and relationships
  - Correlation heatmaps

- **Feature Engineering:**
  - Derived interaction feature `X5*X6`
  - Handled categorical and numerical preprocessing

- **Modeling:**
  - Logistic Regression
  - Decision Tree Classifier
  - Random Forest Classifier
  - Gradient Boosting Classifier
  - Stacking Classifier (ensemble)

- **Evaluation:**
  - Accuracy, precision, recall, F1-score
  - Comparative performance of models

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ full_code.ipynb   # Jupyter Notebook with full workflow
â”œâ”€â”€ README.md         # Project documentation
â””â”€â”€ requirements.txt  # Dependencies
```

âš ï¸ **Note on Data Access**  
The dataset used in this project is **internal and cannot be shared**.  
If you wish to reproduce the workflow, you can replace the dataset with your own CSV file, ensuring it has a similar structure.

## âš™ï¸ Installation
Clone the repository and install dependencies:

```bash
git clone https://github.com/your-username/happiness-survey-analysis.git
cd happiness-survey-analysis
pip install -r requirements.txt
```

## â–¶ï¸ Usage
Open the notebook and run all cells:

```bash
jupyter notebook full_code.ipynb
```

## ğŸ“Š Results
- Gradient Boosting and Stacking classifiers showed strong performance.
- Feature interaction (`X5*X6`) improved predictive power.
- Insights from EDA highlight which features contribute most to survey responses.

## ğŸš€ Future Work
- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)
- Cross-validation for model robustness
- Deployment with a simple web app (Flask/Streamlit)
